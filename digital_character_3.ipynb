{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak_2MzwgEAeR"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from functools import partial\n",
        "#ignore warning messages \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        "import random\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk4MglfeUiyC"
      },
      "outputs": [],
      "source": [
        "import scipy.ndimage as ndimage\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import build_montages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "from keras.utils import np_utils\n",
        "from imutils.contours import sort_contours\n",
        "import imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7EFn0DMfWjF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA1iX2Y0lZew"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSlbCOePFufB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTgIUliOIuUh"
      },
      "outputs": [],
      "source": [
        "newdataset=np.ones((1,3601))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cEVoK29NIXK",
        "outputId": "5080e621-57cd-43bd-8336-90a220fccd02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 3601)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newdataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzUD1kMAIRcD"
      },
      "outputs": [],
      "source": [
        "#                                              RUN THIS IF YOU WANT TO GENERATE 62 CHARACTERS DATASET                               //\n",
        "path = './datasets/English Alphabet Dataset'\n",
        "\n",
        "dir_list = os.listdir(path)\n",
        "for i in dir_list:\n",
        "  print(i)\n",
        "  path_i=os.path.join(path, i)\n",
        "  print(path_i)\n",
        "  img_list=os.listdir(path_i)\n",
        "  for j in img_list:\n",
        "    # an_image = PIL.Image.open(os.path.join(path_i, j))\n",
        "    # an_image.thumbnail((20,20), Image.ANTIALIAS)\n",
        "    # image_sequence = an_image.getdata()\n",
        "    image = cv2.imread(os.path.join(path_i, j))\n",
        "    # image=cv2.resize(image,(60,60))\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,81,8)\n",
        "    kernel = np.ones((5,100), np.uint8)\n",
        "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "    ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "    sorted_ctrs = sort_contours(ctrs,\"top-to-bottom\")[0]\n",
        "    for index, ctr in enumerate(sorted_ctrs):\n",
        "    # Get bounding box\n",
        "      x, y, w, h = cv2.boundingRect(ctr)\n",
        "    # Getting ROI\n",
        "    roi = thresh[y:y+h, x:x+w]\n",
        "    \n",
        "    roi=cv2.resize(roi,(60,60))\n",
        "    # cv2_imshow(roi)\n",
        "    roi=roi.reshape((3600,))\n",
        "    image_array = np.array(roi)\n",
        "    # print(image_array)\n",
        "    # image_array=image_array.reshape((3600))\n",
        "    # image_array=image_array.reshape((1,3600))\n",
        "    image_array=np.insert(image_array,0,int(i)-1)\n",
        "    # print(image_array)\n",
        "    # image_array=np.append(int(i)-1,image_array)\n",
        "    # print(image_array[0])\n",
        "    # print(newdataset[:,0])\n",
        "    image_array=image_array.reshape((1,3601))\n",
        "      # print(image_array.shape)\n",
        "    newdataset=np.append(newdataset,image_array, axis=0)\n",
        "    newdataset=np.append(newdataset,image_array, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iEiLWKvdc9K"
      },
      "outputs": [],
      "source": [
        "#                                              RUN THIS IF YOU WANT TO GENERATE 75 CHARACTERS DATASET                               //\n",
        "path = './datasets/English Alphabet Dataset 3'\n",
        "\n",
        "dir_list = os.listdir(path)\n",
        "for i in dir_list:\n",
        "  print(i)\n",
        "  path_i=os.path.join(path, i)\n",
        "  print(path_i)\n",
        "  img_list=os.listdir(path_i)\n",
        "  for j in img_list:\n",
        "    # an_image = PIL.Image.open(os.path.join(path_i, j))\n",
        "    # an_image.thumbnail((20,20), Image.ANTIALIAS)\n",
        "    # image_sequence = an_image.getdata()\n",
        "    image = cv2.imread(os.path.join(path_i, j))\n",
        "    # image=cv2.resize(image,(60,60))\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,81,8)\n",
        "    kernel = np.ones((5,100), np.uint8)\n",
        "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "    ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "    sorted_ctrs = sort_contours(ctrs,\"top-to-bottom\")[0]\n",
        "    for index, ctr in enumerate(sorted_ctrs):\n",
        "    # Get bounding box\n",
        "      x, y, w, h = cv2.boundingRect(ctr)\n",
        "    # Getting ROI\n",
        "    roi = thresh[y:y+h, x:x+w]\n",
        "    \n",
        "    roi=cv2.resize(roi,(60,60))\n",
        "    # cv2_imshow(roi)\n",
        "    roi=roi.reshape((3600,))\n",
        "    image_array = np.array(roi)\n",
        "    # print(image_array)\n",
        "    # image_array=image_array.reshape((3600))\n",
        "    # image_array=image_array.reshape((1,3600))\n",
        "    image_array=np.insert(image_array,0,int(i)-1)\n",
        "    # print(image_array)\n",
        "    # image_array=np.append(int(i)-1,image_array)\n",
        "    # print(image_array[0])\n",
        "    # print(newdataset[:,0])\n",
        "    image_array=image_array.reshape((1,3601))\n",
        "      # print(image_array.shape)\n",
        "    newdataset=np.append(newdataset,image_array, axis=0)\n",
        "    newdataset=np.append(newdataset,image_array, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7DqhcldI2dB"
      },
      "outputs": [],
      "source": [
        "newdataset=np.delete(newdataset,0,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fty88Mc7JwVQ"
      },
      "outputs": [],
      "source": [
        "np.random.shuffle(newdataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1joUpfvPPNqu"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"./datasets/newdataset-60-75-x2.csv\", newdataset, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGf-zGRxfGdy",
        "outputId": "d46d9466-3ada-4f85-ed7c-424d02894fad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "74.0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.max(newdataset[:,0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "digital-character-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
